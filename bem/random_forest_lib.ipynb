{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T03:42:23.814598Z",
     "start_time": "2023-11-08T03:42:21.715185Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import load_dataset as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_names=['mass', 'semi_major_axis','eccentricity', 'star_metallicity',\n",
    "                'star_radius', 'star_teff','star_mass', 'radius']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee3a52d27b07951f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_dataset(dataset):\n",
    "    dataset_exo = dataset[:-8]\n",
    "    dataset_sol = dataset[-8:]\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e17eaeccc8bbed0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_random_forest(dataset):\n",
    "    dataset_exo = dataset[:-8]\n",
    "    dataset_sol = dataset[-8:]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82c590568ffd298"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_forest_regression(dataset,\n",
    "                             model=saved_pickle_model,\n",
    "                             fit=False):\n",
    "\n",
    "    \"\"\"Split the dataset into a training (75%) and testing set (25%)\n",
    "    Removing 3 outliers planets from both sets\n",
    "\n",
    "    If fit is True:\n",
    "    Fitting the hyperparameters of the random forest regression\n",
    "    otherwise loading a already fitted model\n",
    "\n",
    "\n",
    "    INPUTS: dataset = pandas dataframe with all the exoplanets\n",
    "                      and their planetary and stellar parameters as features\n",
    "            model = random forest model with best fit hyperparameters\n",
    "            fit = boolean, to do the fitting (True) or not (False)\n",
    "    OUPUTS: regr = the random forest regression model\n",
    "            y_test_predict = radius predictions of the test set\n",
    "            train_test_values = arrays with the values of the train and test sets\n",
    "            train_test_sets = pandas dataframes with exoplanets and features names\n",
    "                              as well as the values\"\"\"\n",
    "\n",
    "\n",
    "    # Preparing the training and test sets\n",
    "    # ------------------------------------\n",
    "    # Exoplanet and Solar system dataset\n",
    "    dataset_exo = dataset[:501]\n",
    "    dataset_sol = dataset[501:]\n",
    "\n",
    "    # Separating the data into dependent and independent variables\n",
    "    features = dataset_exo.iloc[:, :-1]   # mass, teq, etc\n",
    "    labels = dataset_exo.iloc[:, -1]      # radius\n",
    "\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                        labels,\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=0)\n",
    "    features_sol = dataset_sol.iloc[:, :-1]\n",
    "    labels_sol = dataset_sol.iloc[:, -1]\n",
    "\n",
    "    X_train_sol, X_test_sol, y_train_sol, y_test_sol = train_test_split(features_sol,\n",
    "                                                                        labels_sol,\n",
    "                                                                        test_size=0.25,\n",
    "                                                                        random_state=0)\n",
    "\n",
    "    X_train = X_train.append(X_train_sol)\n",
    "    y_train = y_train.append(y_train_sol)\n",
    "    X_test = X_test.append(X_test_sol)\n",
    "    y_test = y_test.append(y_test_sol)\n",
    "\n",
    "    # Outliers in the sample\n",
    "    # Remove HATS-12 b from the training set\n",
    "    X_test = X_test.drop(['HATS-12 b'])\n",
    "    y_test = y_test.drop(labels=['HATS-12 b'])\n",
    "    print('\\nHATS-12 b removes from test set\\n')\n",
    "\n",
    "    # Remove K2-95 b from the training set\n",
    "    X_train = X_train.drop(['K2-95 b'])\n",
    "    y_train = y_train.drop(labels=['K2-95 b'])\n",
    "    print('\\nK2-95 b removes from training set\\n')\n",
    "\n",
    "    # Remove Kepler-11 g from the training set\n",
    "    X_train = X_train.drop(['Kepler-11 g'])\n",
    "    y_train = y_train.drop(labels=['Kepler-11 g'])\n",
    "    print('\\nKepler-11 g removes from training set\\n')\n",
    "\n",
    "    train_test_values = [X_train.values, X_test.values,\n",
    "                         y_train.values, y_test.values]\n",
    "    train_test_sets = [X_train, X_test, y_train, y_test]\n",
    "\n",
    "    # Fitting the hyperparameters of the random forest model\n",
    "    # with the grid search method\n",
    "    # ------------------------------------------------------\n",
    "    if fit:\n",
    "        # Setting up the grid of hyperparameters\n",
    "        rf = GridSearchCV(RandomForestRegressor(),\n",
    "                          param_grid={'n_estimators': np.arange(80, 200),\n",
    "                                      'max_depth': np.arange(4, 10),\n",
    "                                      'max_features': np.arange(3, 6),\n",
    "                                      'min_samples_split': np.arange(4, 5)},\n",
    "                          cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "        # Fitting training set - finding best hyperparameters\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Best hyperparameters found by the grid search\n",
    "        print(rf.best_params_)\n",
    "\n",
    "        # Random forest model with the best hyperparameters\n",
    "        regr = RandomForestRegressor(n_estimators=rf.best_params_['n_estimators'],\n",
    "                                     max_depth=rf.best_params_['max_depth'],\n",
    "                                     max_features=rf.best_params_['max_features'],\n",
    "                                     min_samples_split=rf.best_params_['min_samples_split'],\n",
    "                                     random_state=0, oob_score=True)\n",
    "\n",
    "        # Saving the random forest model in a file\n",
    "        outdir = 'bem_output'\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        name_Rf = 'r2_' + str(round(rf.best_score_, 2)) + '_' + str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M\")) + '.pkl'\n",
    "        name_Rf = os.path.join(outdir, name_Rf)\n",
    "\n",
    "        joblib.dump(regr, name_Rf)\n",
    "        print('RF model save in : ', name_Rf)\n",
    "\n",
    "    else:\n",
    "        # Loading the random forest model saved\n",
    "        print('Loading random forest model: ', model)\n",
    "        regr = joblib.load(model)\n",
    "\n",
    "    # Fit the best random forest model to the training set\n",
    "    # ----------------------------------------------------\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the radius for the training and testing sets\n",
    "    y_train_predict = regr.predict(X_train)\n",
    "    y_test_predict = regr.predict(X_test)\n",
    "\n",
    "    # Scores of the random forest\n",
    "    test_score = r2_score(y_test, y_test_predict)\n",
    "    pearson = pearsonr(y_test, y_test_predict)\n",
    "    print(f'Test set, R-2 score: {test_score:>5.3}')\n",
    "    print(f'\\nTest set, Pearson correlation: {pearson[0]:.3}')\n",
    "\n",
    "    # Mean squared errors of the train and test set\n",
    "    print('Root mean squared errors')\n",
    "    print('Train set: ', np.sqrt(np.mean((y_train-y_train_predict)**2)),\n",
    "          '\\nTest set:  ', np.sqrt(np.mean((y_test-y_test_predict)**2)))\n",
    "\n",
    "    # Feature importance\n",
    "    name_features = dataset.columns.tolist()\n",
    "    print('\\nFeature importance')\n",
    "    _ = [print(name, ':  \\t', value)\n",
    "         for name, value\n",
    "         in zip(name_features, regr.feature_importances_)]\n",
    "\n",
    "    return regr, y_test_predict, train_test_values, train_test_sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8444dcafac96690f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
